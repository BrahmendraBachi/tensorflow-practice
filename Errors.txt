ERROR 1:
    ValueError: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.
REASON: (possible)
    1. input_shape attribute in the first conv layer is missing
    2. training the model before it compiles

ERROR 2:
    'Tokenizer' object has no attribute 'vocab_size'
REASON: (possible)
    1. tokenizer has no attribute 'vocab_size'. Instead use len(tokenizer.word_index) to get length